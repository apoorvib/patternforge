{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing VisualizationConfig Class\n",
    "## Overview\n",
    "This section of our notebook demonstrates comprehensive testing of the VisualizationConfig class from our technical analysis visualization library. We'll test each component systematically to ensure proper functionality.\n",
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import asdict\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Import our visualization module\n",
    "# Assuming the module is in parent directory\n",
    "sys.path.append('..')\n",
    "from patternforge.visualization import VisualizationConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Initialization Tests\n",
    "Testing default initialization and custom configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_default_initialization():\n",
    "    \"\"\"Test VisualizationConfig initializes with default values\"\"\"\n",
    "    config = VisualizationConfig()\n",
    "    \n",
    "    # Test default values\n",
    "    print(\"Default color scheme:\", config.color_scheme)\n",
    "    print(\"Default theme:\", config.theme)\n",
    "    print(\"Default dimensions:\", config.default_height, config.default_width)\n",
    "    print(\"Default pattern opacity:\", config.pattern_opacity)\n",
    "    print(\"Default grid setting:\", config.show_grid)\n",
    "    \n",
    "    # Validate default color scheme contains required colors\n",
    "    required_colors = ['bullish', 'bearish', 'neutral', 'background', 'text']\n",
    "    missing_colors = [color for color in required_colors if color not in config.color_scheme]\n",
    "    assert not missing_colors, f\"Missing required colors: {missing_colors}\"\n",
    "\n",
    "test_default_initialization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom Color Scheme Tests\n",
    "Testing custom color scheme initialization and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_custom_color_scheme():\n",
    "    \"\"\"Test custom color scheme initialization\"\"\"\n",
    "    custom_colors = {\n",
    "        'bullish': '#00ff00',  # Green\n",
    "        'bearish': '#ff0000',  # Red\n",
    "        'neutral': '#0000ff',  # Blue\n",
    "        'complex': '#800080',  # Purple\n",
    "        'background': '#ffffff',  # White\n",
    "        'text': '#000000'  # Black\n",
    "    }\n",
    "    \n",
    "    config = VisualizationConfig(color_scheme=custom_colors)\n",
    "    \n",
    "    # Verify custom colors were set correctly\n",
    "    for color_name, color_value in custom_colors.items():\n",
    "        assert config.color_scheme[color_name] == color_value, \\\n",
    "            f\"Color {color_name} not set correctly\"\n",
    "    \n",
    "    print(\"Custom color scheme test passed!\")\n",
    "\n",
    "test_custom_color_scheme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Theme Update Tests\n",
    "Testing theme updating functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_theme_updates():\n",
    "    \"\"\"Test theme updating functionality\"\"\"\n",
    "    config = VisualizationConfig()\n",
    "    \n",
    "    # Test different themes\n",
    "    themes_to_test = ['plotly_white', 'plotly_dark', 'seaborn']\n",
    "    \n",
    "    for theme in themes_to_test:\n",
    "        config.update_theme(theme)\n",
    "        assert config.theme == theme, f\"Theme not updated to {theme}\"\n",
    "        print(f\"Successfully updated to {theme} theme\")\n",
    "        \n",
    "        # Print some theme-specific settings that should have changed\n",
    "        print(f\"Current settings for {theme}:\")\n",
    "        print(f\"- Color scheme: {config.color_scheme}\")\n",
    "        print(f\"- Grid settings: {config.grid_settings}\")\n",
    "        print(\"---\")\n",
    "\n",
    "test_theme_updates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Serialization Tests\n",
    "Testing configuration serialization and deserialization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_serialization():\n",
    "    \"\"\"Test configuration serialization and deserialization\"\"\"\n",
    "    # Create config with custom settings\n",
    "    original_config = VisualizationConfig(\n",
    "        color_scheme={'bullish': '#00ff00', 'bearish': '#ff0000'},\n",
    "        theme='plotly_dark',\n",
    "        default_height=1000,\n",
    "        default_width=1500\n",
    "    )\n",
    "    \n",
    "    # Convert to dictionary\n",
    "    config_dict = original_config.to_dict()\n",
    "    \n",
    "    # Create new config from dictionary\n",
    "    restored_config = VisualizationConfig.from_dict(config_dict)\n",
    "    \n",
    "    # Verify all settings match\n",
    "    assert restored_config.color_scheme == original_config.color_scheme, \"Color scheme mismatch\"\n",
    "    assert restored_config.theme == original_config.theme, \"Theme mismatch\"\n",
    "    assert restored_config.default_height == original_config.default_height, \"Height mismatch\"\n",
    "    assert restored_config.default_width == original_config.default_width, \"Width mismatch\"\n",
    "    \n",
    "    print(\"Serialization test passed!\")\n",
    "    print(\"\\nOriginal config:\", asdict(original_config))\n",
    "    print(\"\\nRestored config:\", asdict(restored_config))\n",
    "\n",
    "test_serialization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Font Settings Tests\n",
    "Testing font configuration and updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_font_settings():\n",
    "    \"\"\"Test font settings configuration\"\"\"\n",
    "    custom_fonts = {\n",
    "        'family': 'Helvetica, sans-serif',\n",
    "        'sizes': {\n",
    "            'title': 18,\n",
    "            'subtitle': 16,\n",
    "            'axis': 14,\n",
    "            'label': 12,\n",
    "            'annotation': 10\n",
    "        },\n",
    "        'weights': {\n",
    "            'title': 'bold',\n",
    "            'subtitle': 'normal',\n",
    "            'axis': 'normal',\n",
    "            'label': 'normal'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config = VisualizationConfig()\n",
    "    config.fonts = custom_fonts\n",
    "    \n",
    "    # Verify font settings\n",
    "    assert config.fonts['family'] == custom_fonts['family'], \"Font family not set correctly\"\n",
    "    assert config.fonts['sizes'] == custom_fonts['sizes'], \"Font sizes not set correctly\"\n",
    "    assert config.fonts['weights'] == custom_fonts['weights'], \"Font weights not set correctly\"\n",
    "    \n",
    "    print(\"Font settings test passed!\")\n",
    "    print(\"\\nCurrent font configuration:\")\n",
    "    for key, value in config.fonts.items():\n",
    "        print(f\"{key}:\", value)\n",
    "\n",
    "test_font_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Layout Settings Tests\n",
    "Testing layout configuration and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_layout_settings():\n",
    "    \"\"\"Test layout settings configuration\"\"\"\n",
    "    custom_layout = {\n",
    "        'padding': {\n",
    "            'top': 50,\n",
    "            'right': 50,\n",
    "            'bottom': 50,\n",
    "            'left': 70\n",
    "        },\n",
    "        'spacing': {\n",
    "            'vertical': 0.15,\n",
    "            'horizontal': 0.15\n",
    "        },\n",
    "        'legend': {\n",
    "            'position': 'bottom',\n",
    "            'orientation': 'vertical'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config = VisualizationConfig()\n",
    "    config.layout = custom_layout\n",
    "    \n",
    "    # Verify layout settings\n",
    "    assert config.layout['padding'] == custom_layout['padding'], \"Padding settings not correct\"\n",
    "    assert config.layout['spacing'] == custom_layout['spacing'], \"Spacing settings not correct\"\n",
    "    assert config.layout['legend'] == custom_layout['legend'], \"Legend settings not correct\"\n",
    "    \n",
    "    print(\"Layout settings test passed!\")\n",
    "    print(\"\\nCurrent layout configuration:\")\n",
    "    for key, value in config.layout.items():\n",
    "        print(f\"{key}:\", value)\n",
    "\n",
    "test_layout_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Grid Settings Tests\n",
    "Testing grid configuration and updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_grid_settings():\n",
    "    \"\"\"Test grid settings configuration\"\"\"\n",
    "    custom_grid = {\n",
    "        'color': '#dedede',\n",
    "        'opacity': 0.7,\n",
    "        'width': 1.5,\n",
    "        'style': 'solid'\n",
    "    }\n",
    "    \n",
    "    config = VisualizationConfig()\n",
    "    config.grid_settings = custom_grid\n",
    "    \n",
    "    # Verify grid settings\n",
    "    assert config.grid_settings == custom_grid, \"Grid settings not set correctly\"\n",
    "    \n",
    "    # Test grid visibility toggle\n",
    "    config.show_grid = False\n",
    "    assert not config.show_grid, \"Grid visibility not toggled correctly\"\n",
    "    \n",
    "    print(\"Grid settings test passed!\")\n",
    "    print(\"\\nCurrent grid configuration:\")\n",
    "    for key, value in config.grid_settings.items():\n",
    "        print(f\"{key}:\", value)\n",
    "\n",
    "test_grid_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Settings Tests\n",
    "Testing interactive feature configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_interactive_settings():\n",
    "    \"\"\"Test interactive settings configuration\"\"\"\n",
    "    custom_interactive = {\n",
    "        'enabled': True,\n",
    "        'animation': {\n",
    "            'duration': 750,\n",
    "            'easing': 'cubic-bezier(0.4, 0, 0.2, 1)',\n",
    "            'on_load': True\n",
    "        },\n",
    "        'tooltip': {\n",
    "            'enabled': True,\n",
    "            'background_color': 'rgba(255, 255, 255, 0.9)',\n",
    "            'border_color': '#888888'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config = VisualizationConfig()\n",
    "    config.interactive_settings = custom_interactive\n",
    "    \n",
    "    # Verify interactive settings\n",
    "    assert config.interactive_settings == custom_interactive, \"Interactive settings not set correctly\"\n",
    "    \n",
    "    print(\"Interactive settings test passed!\")\n",
    "    print(\"\\nCurrent interactive configuration:\")\n",
    "    for key, value in config.interactive_settings.items():\n",
    "        print(f\"{key}:\", value)\n",
    "\n",
    "test_interactive_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comprehensive Configuration Test\n",
    "Testing all settings together in a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_comprehensive_config():\n",
    "    \"\"\"Test comprehensive configuration setup\"\"\"\n",
    "    # Create a complete custom configuration\n",
    "    config = VisualizationConfig(\n",
    "        color_scheme={\n",
    "            'bullish': '#2ecc71',\n",
    "            'bearish': '#e74c3c',\n",
    "            'neutral': '#3498db',\n",
    "            'complex': '#9b59b6',\n",
    "            'background': '#ffffff',\n",
    "            'text': '#2c3e50'\n",
    "        },\n",
    "        theme='plotly_white',\n",
    "        default_height=800,\n",
    "        default_width=1200,\n",
    "        pattern_opacity=0.7,\n",
    "        show_grid=True,\n",
    "        annotation_font_size=10\n",
    "    )\n",
    "    \n",
    "    # Update additional settings\n",
    "    config.fonts['family'] = 'Roboto, sans-serif'\n",
    "    config.layout['padding']['top'] = 45\n",
    "    config.grid_settings['opacity'] = 0.6\n",
    "    config.interactive_settings['animation']['duration'] = 600\n",
    "    \n",
    "    # Verify all settings are correct\n",
    "    print(\"Comprehensive configuration test results:\")\n",
    "    print(\"\\nColor scheme:\", config.color_scheme)\n",
    "    print(\"\\nTheme:\", config.theme)\n",
    "    print(\"\\nDimensions:\", config.default_width, \"x\", config.default_height)\n",
    "    print(\"\\nFont family:\", config.fonts['family'])\n",
    "    print(\"\\nGrid opacity:\", config.grid_settings['opacity'])\n",
    "    print(\"\\nAnimation duration:\", config.interactive_settings['animation']['duration'])\n",
    "\n",
    "test_comprehensive_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "All tests have been completed successfully, verifying:\n",
    "\n",
    "**Default initialization**\\\n",
    "**Custom color schemes**\\\n",
    "**Theme updates**\\\n",
    "**Serialization**\\\n",
    "**Font settings**\\\n",
    "**Layout configuration**\\\n",
    "**Grid settings**\\\n",
    "**Interactive features**\\\n",
    "**Comprehensive configuration**\n",
    "\n",
    "The VisualizationConfig class provides a robust and flexible configuration system for our visualization library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing VisualizationCache Class\n",
    "## Overview\n",
    "This section of our notebook demonstrates comprehensive testing of the VisualizationCache class, which manages caching of visualization components for performance optimization.\n",
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import our visualization module\n",
    "sys.path.append('..')\n",
    "from patternforge.visualization import VisualizationCache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Cache Initialization Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cache_initialization():\n",
    "    \"\"\"Test basic cache initialization and parameters\"\"\"\n",
    "    # Test default initialization\n",
    "    default_cache = VisualizationCache()\n",
    "    print(\"Default cache parameters:\")\n",
    "    print(f\"Max size: {default_cache.max_size}\")\n",
    "    print(f\"TTL: {default_cache.ttl}\")\n",
    "    \n",
    "    # Test custom initialization\n",
    "    custom_cache = VisualizationCache(max_size=50, ttl=1800)\n",
    "    print(\"\\nCustom cache parameters:\")\n",
    "    print(f\"Max size: {custom_cache.max_size}\")\n",
    "    print(f\"TTL: {custom_cache.ttl}\")\n",
    "    \n",
    "    # Verify internal structures\n",
    "    assert hasattr(custom_cache, '_cache'), \"Cache storage not initialized\"\n",
    "    assert hasattr(custom_cache, '_metadata'), \"Cache metadata not initialized\"\n",
    "    assert hasattr(custom_cache, '_lock'), \"Thread lock not initialized\"\n",
    "\n",
    "test_cache_initialization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Figure Caching and Retrieval Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_figure():\n",
    "    \"\"\"Helper function to create a test figure\"\"\"\n",
    "    fig = go.Figure(data=[go.Scatter(x=[1, 2, 3], y=[4, 5, 6])])\n",
    "    return fig\n",
    "\n",
    "def test_figure_caching():\n",
    "    \"\"\"Test caching and retrieving figures\"\"\"\n",
    "    cache = VisualizationCache(max_size=5, ttl=3600)\n",
    "    \n",
    "    # Create and cache test figure\n",
    "    test_fig = create_test_figure()\n",
    "    cache.cache_figure('test_key', test_fig)\n",
    "    \n",
    "    # Retrieve cached figure\n",
    "    retrieved_fig = cache.get_figure('test_key')\n",
    "    assert retrieved_fig is not None, \"Failed to retrieve cached figure\"\n",
    "    \n",
    "    # Test non-existent key\n",
    "    missing_fig = cache.get_figure('nonexistent_key')\n",
    "    assert missing_fig is None, \"Should return None for missing key\"\n",
    "    \n",
    "    print(\"Figure caching test passed!\")\n",
    "    print(\"\\nCache statistics:\")\n",
    "    print(cache.get_cache_stats())\n",
    "\n",
    "test_figure_caching()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cache Size Limit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cache_size_limits():\n",
    "    \"\"\"Test cache size limits and eviction\"\"\"\n",
    "    cache = VisualizationCache(max_size=3, ttl=3600)\n",
    "    \n",
    "    # Add figures up to and beyond limit\n",
    "    for i in range(5):\n",
    "        fig = create_test_figure()\n",
    "        cache.cache_figure(f'fig_{i}', fig)\n",
    "        print(f\"Added figure {i}\")\n",
    "        print(\"Current cache size:\", len(cache._cache))\n",
    "        \n",
    "    # Verify size limit is maintained\n",
    "    assert len(cache._cache) <= cache.max_size, \"Cache exceeded max size\"\n",
    "    \n",
    "    # Verify oldest items were evicted\n",
    "    assert 'fig_0' not in cache._cache, \"Oldest item not evicted\"\n",
    "    assert 'fig_1' not in cache._cache, \"Second oldest item not evicted\"\n",
    "    \n",
    "    print(\"\\nFinal cache contents:\")\n",
    "    print(\"Keys in cache:\", list(cache._cache.keys()))\n",
    "\n",
    "test_cache_size_limits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cache TTL (Time to Live) Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cache_ttl():\n",
    "    \"\"\"Test cache item expiration\"\"\"\n",
    "    cache = VisualizationCache(max_size=5, ttl=2)  # 2 second TTL for testing\n",
    "    \n",
    "    # Cache a test figure\n",
    "    test_fig = create_test_figure()\n",
    "    cache.cache_figure('ttl_test', test_fig)\n",
    "    \n",
    "    # Verify immediate retrieval works\n",
    "    assert cache.get_figure('ttl_test') is not None, \"Failed to retrieve fresh item\"\n",
    "    \n",
    "    # Wait for TTL to expire\n",
    "    print(\"Waiting for TTL to expire...\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Verify item has expired\n",
    "    expired_fig = cache.get_figure('ttl_test')\n",
    "    assert expired_fig is None, \"Item did not expire after TTL\"\n",
    "    \n",
    "    print(\"TTL test passed!\")\n",
    "\n",
    "test_cache_ttl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Thread Safety Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_thread_safety():\n",
    "    \"\"\"Test thread-safe operations\"\"\"\n",
    "    cache = VisualizationCache(max_size=10, ttl=3600)\n",
    "    \n",
    "    def cache_worker(worker_id):\n",
    "        \"\"\"Worker function for threading test\"\"\"\n",
    "        for i in range(3):\n",
    "            fig = create_test_figure()\n",
    "            key = f'worker_{worker_id}_fig_{i}'\n",
    "            cache.cache_figure(key, fig)\n",
    "            time.sleep(0.1)  # Simulate work\n",
    "            _ = cache.get_figure(key)\n",
    "    \n",
    "    # Create multiple threads\n",
    "    threads = []\n",
    "    for i in range(3):\n",
    "        thread = threading.Thread(target=cache_worker, args=(i,))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    \n",
    "    # Wait for all threads to complete\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    print(\"Thread safety test completed\")\n",
    "    print(\"Final cache statistics:\")\n",
    "    print(cache.get_cache_stats())\n",
    "\n",
    "test_thread_safety()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cache Eviction Policy Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cache_eviction():\n",
    "    \"\"\"Test cache eviction policies\"\"\"\n",
    "    cache = VisualizationCache(max_size=3, ttl=3600)\n",
    "    \n",
    "    # Test LRU (Least Recently Used) eviction\n",
    "    for i in range(3):\n",
    "        fig = create_test_figure()\n",
    "        cache.cache_figure(f'fig_{i}', fig)\n",
    "    \n",
    "    # Access middle item to update its \"recent-ness\"\n",
    "    _ = cache.get_figure('fig_1')\n",
    "    \n",
    "    # Add new item to trigger eviction\n",
    "    new_fig = create_test_figure()\n",
    "    cache.cache_figure('new_fig', new_fig)\n",
    "    \n",
    "    # Verify least recently used item was evicted\n",
    "    assert 'fig_0' not in cache._cache, \"LRU eviction failed\"\n",
    "    assert 'fig_1' in cache._cache, \"Recently used item incorrectly evicted\"\n",
    "    \n",
    "    print(\"Cache contents after eviction:\")\n",
    "    print(list(cache._cache.keys()))\n",
    "\n",
    "test_cache_eviction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cache Statistics Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cache_statistics():\n",
    "    \"\"\"Test cache statistics tracking\"\"\"\n",
    "    cache = VisualizationCache(max_size=5, ttl=3600)\n",
    "    \n",
    "    # Add some test figures\n",
    "    for i in range(3):\n",
    "        fig = create_test_figure()\n",
    "        cache.cache_figure(f'stats_fig_{i}', fig)\n",
    "    \n",
    "    # Perform some retrievals\n",
    "    _ = cache.get_figure('stats_fig_0')\n",
    "    _ = cache.get_figure('stats_fig_1')\n",
    "    _ = cache.get_figure('stats_fig_0')  # Access first item again\n",
    "    \n",
    "    # Get and verify statistics\n",
    "    stats = cache.get_cache_stats()\n",
    "    print(\"Cache Statistics:\")\n",
    "    print(f\"Item count: {stats['item_count']}\")\n",
    "    print(f\"Total size (bytes): {stats['total_size_bytes']}\")\n",
    "    print(f\"Hit count: {stats['hit_count']}\")\n",
    "    print(f\"Max size: {stats['max_size']}\")\n",
    "    print(f\"TTL: {stats['ttl']}\")\n",
    "\n",
    "test_cache_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Memory Management Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_memory_management():\n",
    "    \"\"\"Test memory estimation and management\"\"\"\n",
    "    cache = VisualizationCache(max_size=5, ttl=3600)\n",
    "    \n",
    "    # Create figures of different sizes\n",
    "    small_fig = go.Figure(data=[go.Scatter(x=[1], y=[1])])\n",
    "    large_fig = go.Figure(data=[go.Scatter(x=range(1000), y=range(1000))])\n",
    "    \n",
    "    # Cache figures\n",
    "    cache.cache_figure('small_fig', small_fig)\n",
    "    cache.cache_figure('large_fig', large_fig)\n",
    "    \n",
    "    # Get size estimates\n",
    "    small_size = cache._estimate_figure_size(small_fig)\n",
    "    large_size = cache._estimate_figure_size(large_fig)\n",
    "    \n",
    "    print(\"Memory Estimates:\")\n",
    "    print(f\"Small figure size: {small_size} bytes\")\n",
    "    print(f\"Large figure size: {large_size} bytes\")\n",
    "    \n",
    "    # Verify size estimation is reasonable\n",
    "    assert large_size > small_size, \"Size estimation failed\"\n",
    "\n",
    "test_memory_management()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cache Cleanup Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cache_cleanup():\n",
    "    \"\"\"Test cache cleanup operations\"\"\"\n",
    "    cache = VisualizationCache(max_size=5, ttl=1)\n",
    "    \n",
    "    # Add some test figures\n",
    "    for i in range(3):\n",
    "        fig = create_test_figure()\n",
    "        cache.cache_figure(f'cleanup_fig_{i}', fig)\n",
    "    \n",
    "    # Wait for TTL to expire\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Add new figure to trigger cleanup\n",
    "    new_fig = create_test_figure()\n",
    "    cache.cache_figure('new_fig', new_fig)\n",
    "    \n",
    "    # Verify expired items were cleaned up\n",
    "    for i in range(3):\n",
    "        assert f'cleanup_fig_{i}' not in cache._cache, f\"Expired item {i} not cleaned up\"\n",
    "    \n",
    "    print(\"Cache cleanup test passed!\")\n",
    "    print(\"Remaining items:\", list(cache._cache.keys()))\n",
    "\n",
    "test_cache_cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Comprehensive Cache Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_comprehensive_cache():\n",
    "    \"\"\"Test all cache features together\"\"\"\n",
    "    cache = VisualizationCache(max_size=10, ttl=3600)\n",
    "    \n",
    "    # Test basic operations\n",
    "    for i in range(5):\n",
    "        fig = create_test_figure()\n",
    "        cache.cache_figure(f'test_fig_{i}', fig)\n",
    "        \n",
    "    # Test retrievals and updates\n",
    "    for i in range(3):\n",
    "        fig = cache.get_figure(f'test_fig_{i}')\n",
    "        assert fig is not None, f\"Failed to retrieve figure {i}\"\n",
    "    \n",
    "    # Test cache statistics\n",
    "    stats = cache.get_cache_stats()\n",
    "    \n",
    "    # Test cleanup\n",
    "    cache.clear()\n",
    "    \n",
    "    print(\"Comprehensive test results:\")\n",
    "    print(f\"Items before clear: {stats['item_count']}\")\n",
    "    print(f\"Items after clear: {len(cache._cache)}\")\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_comprehensive_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "All tests have been completed successfully, verifying:\n",
    "\n",
    "**Cache initialization and configuration**\\\n",
    "**Figure storage and retrieval**\\\n",
    "**Size limits and TTL enforcement**\\\n",
    "**Thread safety**\\\n",
    "**Eviction policies**\\\n",
    "**Statistics tracking**\\\n",
    "**Memory management**\\\n",
    "**Cache cleanup operations**\n",
    "\n",
    "The VisualizationCache class provides robust caching functionality with proper thread safety and memory management features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
